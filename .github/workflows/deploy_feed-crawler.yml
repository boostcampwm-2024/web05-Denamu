name: Feed-Crawler Deployment

on:
  push:
    branches: [main]
    paths: ['feed-crawler/**', 'docker-compose/docker-compose.prod.yml']
  workflow_dispatch:

permissions:
  contents: read
  packages: write

env:
  GHCR_URL: ${{ vars.GHCR }}
  FEED_CRAWLER_IMAGE: ${{ vars.GHCR }}/feed-crawler
  FEED_CRAWLER_TAG: sha-${{ github.sha }}
  SERVICE: feed-crawler
  FEED-CRAWLER_ENV_DIR: /var/prod_config/feed-crawler
  FEED-CRAWLER_ENV_FILE: /var/prod_config/feed-crawler/.env.prod
  INFRA_ENV_FILE: /var/prod_config/infra/.env.prod
  COMPOSE_FILE: docker-compose/docker-compose.prod.yml

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: QEMU 멀티 아키텍쳐 에뮬레이터
        uses: docker/setup-qemu-action@v3

      - name: Buildx 멀티 아키텍쳐 빌더
        uses: docker/setup-buildx-action@v3

      - name: GHCR 로그인
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_GITHUB_TOKEN }}

      - name: Docker 이미지 Build 및 Push
        uses: docker/build-push-action@v6
        with:
          context: ./feed-crawler
          file: ./feed-crawler/docker/Dockerfile.prod
          push: true
          platforms: linux/amd64,linux/arm64
          tags: |
            ${{ env.FEED_CRAWLER_IMAGE }}:${{ env.FEED_CRAWLER_TAG }}
            ${{ env.FEED_CRAWLER_IMAGE }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    runs-on: [self-hosted, prod]
    needs: build-and-push # Build 및 Push가 끝나면 시작
    steps:
      - name: 코드 체크아웃
        uses: actions/checkout@v4

      - name: GHCR 로그인 (prod)
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_GITHUB_TOKEN }}

      - name: 환경변수 최신화
        run: |
          sudo mkdir -p "${{env.FEED-CRAWLER_ENV_DIR}}"
          sudo install -m 600 /dev/null "${{env.FEED-CRAWLER_ENV_FILE}}"
          {
            echo "AI_API_KEY=${{ secrets.AI_API_KEY }}"
            echo "DB_HOST=${{ secrets.DB_HOST }}"
            echo "DB_NAME=${{ secrets.DB_NAME }}"
            echo "DB_PASSWORD=${{ secrets.DB_PASSWORD }}"
            echo "DB_PORT=${{ secrets.DB_PORT }}"
            echo "DB_USER=${{ secrets.DB_USER }}"
            echo "RABBITMQ_HOST=${{ secrets.RABBITMQ_HOST }}"
            echo "RABBITMQ_PASSWORD=${{ secrets.RABBITMQ_PASSWORD }}"
            echo "RABBITMQ_PORT=${{ secrets.RABBITMQ_PORT }}"
            echo "RABBITMQ_USER=${{ secrets.RABBITMQ_USER }}"
            echo "REDIS_HOST=${{ secrets.REDIS_HOST }}"
            echo "REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}"
            echo "REDIS_PORT=${{ secrets.REDIS_PORT }}"
            echo "REDIS_USER=${{ secrets.REDIS_USER }}"
            echo "TIME_INTERVAL=${{ vars.FEED_CRAWLER_TIME_INTERVAL }}"
            echo "AI_RATE_LIMIT_COUNT=${{ vars.AI_RATE_LIMIT_COUNT }}"
            } | sudo tee "${{env.FEED-CRAWLER_ENV_FILE}}" >/dev/null

      - name: Docker 이미지 Pull & 서비스 재시작
        run: |
          set -a
          source ${{ env.FEED-CRAWLER_ENV_FILE }}
          source ${{ env.INFRA_ENV_FILE }}
          set +a

          docker compose -f "${{env.COMPOSE_FILE}}" pull "${{env.SERVICE}}"
          docker compose -f "${{env.COMPOSE_FILE}}" up -d --no-deps --force-recreate "${{env.SERVICE}}"
          docker image prune -f
